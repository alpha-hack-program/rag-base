app: rag-lsd
partOf: rag-base

namespace: rag-base
# createNamespace: true

argocdNamespace: openshift-gitops

vcs:
  uri: https://github.com/alpha-hack-program/rag-lsd.git
  ref: main
  name: alpha-hack-program/rag-lsd
  path: .
  # sourceSecret: git-pat-bc-secret

milvusDbPath: ~/.llama/milvus.db

fmsOchestratorUrl: http://localhost

lsdImage: quay.io/opendatahub/llama-stack:odh
lsdPort: 8321

lsdResources:
  limits:
    cpu: '2'
    memory: 12Gi
  requests:
    cpu: 250m
    memory: 500Mi

mcpServers:
  - id: mcp::bon-calculadora
    provider_id: model-context-protocol
    endpoint:
      uri: "http://bon-calculadora:8000/sse"

models:
  - name: granite-3-3-8b
    url: http://granite-3-3-8b-predictor:8080/v1
    model: granite-3-3-8b-instruct
    api_key: ""
    tls_verify: false
    max_tokens: 12000
  - name: llama-3-1-8b-w4a16
    url: http://llama-3-1-8b-w4a16-predictor:8080/v1
    model: meta-llama/Llama-3.1-8B-Instruct
    api_key: ""
    tls_verify: false
    max_tokens: 12000

prompts:
  - name: context
    description: "Prompt for answering general questions with context"
    template: |
      Given the following context:
      <context>
      {context}
      </context>

      Answer the question: {query}
      Don't use any information outside the context provided. Don't make up any information. If you don't know the answer, just say 'I don't know'.

  - name: default
    description: "Prompt for answering questions without context"
    template: |
      Answer the question: {query}
      Don't use any context. Don't make up any information. If you don't know the answer, just say 'I don't know'.
  
