apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: {{ .Values.app }}
  namespace: {{ .Values.namespace }}
spec:
  replicas: 1
  server:
    containerSpec:
      env:
        {{- $appName := .Values.app }}
        {{- range .Values.models }}
        - name: {{ include "rag-lsd.envVarName" .name }}_MODEL
          valueFrom:
            secretKeyRef:
              key: {{ include "rag-lsd.envVarName" .name }}_MODEL
              name: {{ $appName }}-env
        - name: {{ include "rag-lsd.envVarName" .name }}_URL
          valueFrom:
            secretKeyRef:
              key: {{ include "rag-lsd.envVarName" .name }}_URL
              name: {{ $appName }}-env
        {{- if .api_key }}
        - name: {{ include "rag-lsd.envVarName" .name }}_API_KEY
          valueFrom:
            secretKeyRef:
              key: {{ include "rag-lsd.envVarName" .name }}_API_KEY
              name: {{ $appName }}-env
        {{- end }}
        {{- if .tls_verify }}
        - name: {{ include "rag-lsd.envVarName" .name }}_TLS_VERIFY
          valueFrom:
            secretKeyRef:
              key: {{ include "rag-lsd.envVarName" .name }}_TLS_VERIFY
              name: {{ $appName }}-env
        {{- end }}
        {{- if .max_tokens }}
        - name: {{ include "rag-lsd.envVarName" .name }}_MAX_TOKENS
          valueFrom:
            secretKeyRef:
              key: {{ include "rag-lsd.envVarName" .name }}_MAX_TOKENS
              name: {{ $appName }}-env
        {{- end }}
        {{- end }}
        - name: MILVUS_DB_PATH
          value: {{ .Values.milvusDbPath }}
        - name: FMS_ORCHESTRATOR_URL
          value: {{ .Values.fmsOchestratorUrl }}
      name: llama-stack
      port: {{ .Values.lsdPort | default 8321 }}
      {{- if .Values.lsdResources }}
      resources:
        {{- if .Values.lsdResources.limits }}
        limits:
          cpu: {{ .Values.lsdResources.limits.cpu | default "2" }}
          memory: {{ .Values.lsdResources.limits.memory | default "12Gi" }}
        {{- end }}
        {{- if .Values.lsdResources.requests }}
        requests:
          cpu: {{ .Values.lsdResources.requests.cpu | default "250m" }}
          memory: {{ .Values.lsdResources.requests.memory | default "1Gi" }}
        {{- end }}
      {{- end }}
      apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: my-llama-stack
  namespace: default
spec:
  replicas: 1
  server:
    # Distribution configuration - you can use either 'name' for predefined distributions
    # or 'image' for a direct container image reference
    distribution:
      name: "local"  # or specify image: "your-registry/llama-stack:tag"
    
    # Container specification
    containerSpec:
      name: llama-stack
      port: 8000
      resources:
        requests:
          memory: "2Gi"
          cpu: "1000m"
        limits:
          memory: "4Gi"
          cpu: "2000m"
    
    # Pod-level overrides to mount the secret
    podOverrides:
      # Define volumes at the pod level
      volumes:
        - name: run-config
          secret:
            secretName: {{ .Values.app }}-run
            items:
              - key: run.yaml
                path: run.yaml
            defaultMode: 0644
      # Mount the volume in the container
      volumeMounts:
        - name: run-config
          mountPath: /opt/app-root/run.yaml
          subPath: run.yaml
          readOnly: true
    distribution:
      image: '{{ .Values.lsdImage }}'
    storage:
      size: 5Gi